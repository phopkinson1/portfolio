{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4210b121",
   "metadata": {},
   "source": [
    "# Wine classification using the k-Nearest Neighbors algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181daf74",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242365c7",
   "metadata": {},
   "source": [
    "K-nearest neighbors (KNN) is a simple yet powerful supervised machine learning algorithm that can be used for both classification and regression tasks. It works by finding the K closest data points in the training set to a given test point, and using their labels or values to make predictions for the test point. In this project, we will load and prepare the dataset, explain how the algorithm works, fit it to the data and make the predictions, then finally we will evaluate the performance of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8640c80",
   "metadata": {},
   "source": [
    "## Import of libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f788a961",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabcf13d",
   "metadata": {},
   "source": [
    "## Import and preprocessing of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a95e8ca",
   "metadata": {},
   "source": [
    "In this section, we will import and scale the dataset, and then remove any outliers present in the dataset. We have to scale the data to ensure all features contribute equally to the overall classification, otherwise the model will be biased towards features with a larger scale and this can lead to reduced performance in our model. Then, we also have to remove the outliers for the kNN algorithm because if there are outliers in the dataset, they will be considered as k-Nearest neighbors despite the fact that they are not representive of the typical values in the dataset. This can lead to incorrect predictions and reduce the performance of the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "578ac569",
   "metadata": {},
   "outputs": [],
   "source": [
    "wine = load_wine()\n",
    "X = wine.data\n",
    "y = wine.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9e213fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the dataset\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Calculate the Z-score of each feature\n",
    "z_train = np.abs(stats.zscore(X))\n",
    "\n",
    "# Define a threshold for outliers\n",
    "threshold = 3\n",
    "\n",
    "# Find the indices of outliers\n",
    "outlier_indices = np.where(z_train > threshold)\n",
    "\n",
    "# Remove the outliers from the dataset\n",
    "X_filtered = np.delete(X_scaled, outlier_indices[0], axis=0)\n",
    "y_filtered = np.delete(y, outlier_indices[0], axis=0)\n",
    "\n",
    "# Split the data into train and test set\n",
    "x_train, x_test, y_train, y_test = train_test_split(X_filtered, y_filtered, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b189542",
   "metadata": {},
   "source": [
    "## k-Nearest Neighbors classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523afff8",
   "metadata": {},
   "source": [
    "The kNN algorithm is a classifier that aims to correctly class groups based on their similarity to the exist training data using a distance metric. The kNN algorithm aims to classify a new instance by computing its distances to all instances in the training data using a distance metric, and selecting the k instances with the smallest distances. The predicted class of the new instance is then determined by a majority vote among the k nearest neighbors. This process is repeated for each new instance to be classified. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "edb6d08f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-12 {color: black;background-color: white;}#sk-container-id-12 pre{padding: 0;}#sk-container-id-12 div.sk-toggleable {background-color: white;}#sk-container-id-12 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-12 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-12 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-12 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-12 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-12 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-12 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-12 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-12 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-12 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-12 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-12 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-12 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-12 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-12 div.sk-item {position: relative;z-index: 1;}#sk-container-id-12 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-12 div.sk-item::before, #sk-container-id-12 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-12 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-12 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-12 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-12 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-12 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-12 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-12 div.sk-label-container {text-align: center;}#sk-container-id-12 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-12 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-12\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" checked><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "01c29c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = knn.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "965f1a30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation report\n",
      "\n",
      "Accuracy: 97.619 %\n",
      "F1 score: 97.637 %\n",
      "Recall: 97.619 %\n",
      "Precision: 97.835 %\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print('Evaluation report\\n')\n",
    "print(f'Accuracy: {accuracy * 100:.3f} %')\n",
    "print(f'F1 score: {f1 * 100:.3f} %')\n",
    "print(f'Recall: {recall * 100:.3f} %')\n",
    "print(f'Precision: {precision * 100:.3f} %')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
