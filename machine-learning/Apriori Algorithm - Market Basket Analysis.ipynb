{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e21d2f21",
   "metadata": {},
   "source": [
    "# Apriori algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251e470e",
   "metadata": {},
   "source": [
    "The Apriori algorithm is a association rule, which can determine associations and relationships in large dataset. One example is market based transactions, which allows retailers to determine which items consumers buy together most frequently. Given a set of transactions, we can determine what the other items the consumer has bought based on a subset of their transaction. This is where the Apriori algorithm gets its name because it uses prior knowledge of frequent itemset properties.\n",
    "\n",
    "The algorithm assumes that if an itemset is frequent, then all it subsets must be frequent, converselty, if an itemset is infrequent then all of its supersets must be infrequent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb7c81b",
   "metadata": {},
   "source": [
    "## How the algorithm works"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "616ad422",
   "metadata": {},
   "source": [
    "The algorithm works in two phases: \n",
    "* Finding frequent itemsets - in this phase, the algorithm scans the dataset for all items that meet the minimum support threshold. The support of the itemset is the proportion of transactions that itemset is present in. The algorithm uses a level-wise approach, finding all frequent itemsets of size 1 then size 2 and so on.\n",
    "* Generating association rules - the algorithm generates the association rules between frequent itemsets. An association rule is a statement of the form A â†’ B, where A and B are itemsets and A is the antecedent (the left-hand side of the rule) and B is the consequent (the right-hand side of the rule). The algorithm generates all possible rules from each frequent itemset and evaluates their strength based on a measure called the confidence. The confidence is all the transactions that include both A and B, divided by the proportion of transactions that contain A. The algorithm selects those association rules which meet the minimum confidence threshold. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca4229f",
   "metadata": {},
   "source": [
    "## Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19d580c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from apyori import apriori"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51aa46f",
   "metadata": {},
   "source": [
    "## Import of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e1e5218e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>shrimp</td>\n",
       "      <td>almonds</td>\n",
       "      <td>avocado</td>\n",
       "      <td>vegetables mix</td>\n",
       "      <td>green grapes</td>\n",
       "      <td>whole weat flour</td>\n",
       "      <td>yams</td>\n",
       "      <td>cottage cheese</td>\n",
       "      <td>energy drink</td>\n",
       "      <td>tomato juice</td>\n",
       "      <td>low fat yogurt</td>\n",
       "      <td>green tea</td>\n",
       "      <td>honey</td>\n",
       "      <td>salad</td>\n",
       "      <td>mineral water</td>\n",
       "      <td>salmon</td>\n",
       "      <td>antioxydant juice</td>\n",
       "      <td>frozen smoothie</td>\n",
       "      <td>spinach</td>\n",
       "      <td>olive oil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>burgers</td>\n",
       "      <td>meatballs</td>\n",
       "      <td>eggs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chutney</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>turkey</td>\n",
       "      <td>avocado</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mineral water</td>\n",
       "      <td>milk</td>\n",
       "      <td>energy bar</td>\n",
       "      <td>whole wheat rice</td>\n",
       "      <td>green tea</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0          1           2                 3             4   \\\n",
       "0         shrimp    almonds     avocado    vegetables mix  green grapes   \n",
       "1        burgers  meatballs        eggs               NaN           NaN   \n",
       "2        chutney        NaN         NaN               NaN           NaN   \n",
       "3         turkey    avocado         NaN               NaN           NaN   \n",
       "4  mineral water       milk  energy bar  whole wheat rice     green tea   \n",
       "\n",
       "                 5     6               7             8             9   \\\n",
       "0  whole weat flour  yams  cottage cheese  energy drink  tomato juice   \n",
       "1               NaN   NaN             NaN           NaN           NaN   \n",
       "2               NaN   NaN             NaN           NaN           NaN   \n",
       "3               NaN   NaN             NaN           NaN           NaN   \n",
       "4               NaN   NaN             NaN           NaN           NaN   \n",
       "\n",
       "               10         11     12     13             14      15  \\\n",
       "0  low fat yogurt  green tea  honey  salad  mineral water  salmon   \n",
       "1             NaN        NaN    NaN    NaN            NaN     NaN   \n",
       "2             NaN        NaN    NaN    NaN            NaN     NaN   \n",
       "3             NaN        NaN    NaN    NaN            NaN     NaN   \n",
       "4             NaN        NaN    NaN    NaN            NaN     NaN   \n",
       "\n",
       "                  16               17       18         19  \n",
       "0  antioxydant juice  frozen smoothie  spinach  olive oil  \n",
       "1                NaN              NaN      NaN        NaN  \n",
       "2                NaN              NaN      NaN        NaN  \n",
       "3                NaN              NaN      NaN        NaN  \n",
       "4                NaN              NaN      NaN        NaN  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\pjhop\\OneDrive\\Documents\\Programming & Coding\\Python\\Projects\\Datasets\\Market_Basket_Optimisation.csv\", header=None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "45ac8948",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7501, 20)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "37c5ce74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversion from df to list format \n",
    "transactions = []\n",
    "for i in range(0, 7501):\n",
    "    transactions.append([str(df.values[i,j]) for j in range(0, 20)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040c90d4",
   "metadata": {},
   "source": [
    "The code above stores the transactions in a list format by iterating across the columns and rows in the DataFrame and appending the string values to a `transactions` list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec8bc72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rules = apriori(transactions=transactions, min_support=0.005, min_confidence=0.2, min_lift=3, min_length=2, max_length=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f8969c",
   "metadata": {},
   "source": [
    "The apriori class takes a few parameters, which can be altered to give different outcomes:\n",
    "* `transactions` takes the list format of the transaction data.\n",
    "* `min_support` which is a threshold which specifies the minimum amount of support an item must have to be considered 'frequent'.\n",
    "* `min_confidence` specifies the minimum amount of people who bought one item must have bought the other, in this case 20% of people who bought one item must have bought the other.\n",
    "* `min_lift` considers the lift, which is a measure of the strength of the association, by having a minimum lift we consider only strong associations.\n",
    "* `min_length` and `max_length` specify the minimum and maximum number of items which must be present in each itemset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "867fbc37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RelationRecord(items=frozenset({'escalope', 'mushroom cream sauce'}), support=0.005732568990801226, ordered_statistics=[OrderedStatistic(items_base=frozenset({'mushroom cream sauce'}), items_add=frozenset({'escalope'}), confidence=0.3006993006993007, lift=3.790832696715049)]), RelationRecord(items=frozenset({'escalope', 'pasta'}), support=0.005865884548726837, ordered_statistics=[OrderedStatistic(items_base=frozenset({'pasta'}), items_add=frozenset({'escalope'}), confidence=0.3728813559322034, lift=4.700811850163794)]), RelationRecord(items=frozenset({'ground beef', 'herb & pepper'}), support=0.015997866951073192, ordered_statistics=[OrderedStatistic(items_base=frozenset({'herb & pepper'}), items_add=frozenset({'ground beef'}), confidence=0.3234501347708895, lift=3.2919938411349285)]), RelationRecord(items=frozenset({'ground beef', 'tomato sauce'}), support=0.005332622317024397, ordered_statistics=[OrderedStatistic(items_base=frozenset({'tomato sauce'}), items_add=frozenset({'ground beef'}), confidence=0.3773584905660377, lift=3.840659481324083)]), RelationRecord(items=frozenset({'olive oil', 'whole wheat pasta'}), support=0.007998933475536596, ordered_statistics=[OrderedStatistic(items_base=frozenset({'whole wheat pasta'}), items_add=frozenset({'olive oil'}), confidence=0.2714932126696833, lift=4.122410097642296)]), RelationRecord(items=frozenset({'shrimp', 'pasta'}), support=0.005065991201173177, ordered_statistics=[OrderedStatistic(items_base=frozenset({'pasta'}), items_add=frozenset({'shrimp'}), confidence=0.3220338983050847, lift=4.506672147735896)])]\n"
     ]
    }
   ],
   "source": [
    "results = list(rules)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7992e91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inspect(results):\n",
    "    lhs         = [tuple(result[2][0][0])[0] for result in results]\n",
    "    rhs         = [tuple(result[2][0][1])[0] for result in results]\n",
    "    supports    = [result[1] for result in results]\n",
    "    confidences = [result[2][0][2] for result in results]\n",
    "    lifts       = [result[2][0][3] for result in results]\n",
    "    return list(zip(lhs, rhs, supports, confidences, lifts))\n",
    "resultsinDataFrame = pd.DataFrame(inspect(results), columns = ['Left Hand Side', 'Right Hand Side', 'Support', 'Confidence', 'Lift'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5044f6e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Left Hand Side</th>\n",
       "      <th>Right Hand Side</th>\n",
       "      <th>Support</th>\n",
       "      <th>Confidence</th>\n",
       "      <th>Lift</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mushroom cream sauce</td>\n",
       "      <td>escalope</td>\n",
       "      <td>0.005733</td>\n",
       "      <td>0.300699</td>\n",
       "      <td>3.790833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pasta</td>\n",
       "      <td>escalope</td>\n",
       "      <td>0.005866</td>\n",
       "      <td>0.372881</td>\n",
       "      <td>4.700812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>herb &amp; pepper</td>\n",
       "      <td>ground beef</td>\n",
       "      <td>0.015998</td>\n",
       "      <td>0.323450</td>\n",
       "      <td>3.291994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tomato sauce</td>\n",
       "      <td>ground beef</td>\n",
       "      <td>0.005333</td>\n",
       "      <td>0.377358</td>\n",
       "      <td>3.840659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>whole wheat pasta</td>\n",
       "      <td>olive oil</td>\n",
       "      <td>0.007999</td>\n",
       "      <td>0.271493</td>\n",
       "      <td>4.122410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>pasta</td>\n",
       "      <td>shrimp</td>\n",
       "      <td>0.005066</td>\n",
       "      <td>0.322034</td>\n",
       "      <td>4.506672</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Left Hand Side Right Hand Side   Support  Confidence      Lift\n",
       "0  mushroom cream sauce        escalope  0.005733    0.300699  3.790833\n",
       "1                 pasta        escalope  0.005866    0.372881  4.700812\n",
       "2         herb & pepper     ground beef  0.015998    0.323450  3.291994\n",
       "3          tomato sauce     ground beef  0.005333    0.377358  3.840659\n",
       "4     whole wheat pasta       olive oil  0.007999    0.271493  4.122410\n",
       "5                 pasta          shrimp  0.005066    0.322034  4.506672"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultsinDataFrame.head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bde8707",
   "metadata": {},
   "source": [
    "## Limitations of the algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e771aad",
   "metadata": {},
   "source": [
    "The Apriori algorithm is extremely slow, because it relies on repeatedly scanning a large dataset for frequent itemsets. It will then further break this down into smaller subsets which will then be tested. This means it be very slow and inefficient when there are large datasets."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
